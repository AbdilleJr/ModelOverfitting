This repository contains Python code for generating synthetic data and training a Decision Tree classifier on it. The classifier is then evaluated on both training and testing data. The repository includes a ReadMe file for understanding the code and its functionalities.
The code starts by importing the necessary libraries. These libraries are like tools that help us perform specific tasks. For example, numpy is used for numerical computations, matplotlib.pyplot is used for plotting graphs, and sklearn is used for machine learning tasks.
The code then generates synthetic data for binary classification. This means it creates data that can be classified into two categories. The data is generated from Gaussian distributions (which are like bell curves) and a uniform distribution. These distributions are used to create instances for Class 1 and Class 0 respectively. The generated data points are stored in the variables X (features) and y (labels).
A Decision Tree classifier is initialized with specific parameters like the criterion for splitting the data (in this case, 'entropy') and the maximum depth of the tree The classifier is then trained on the generated data using the fit method.
The decision tree is visualized using Graphviz and Pydotplus libraries. These libraries help us create a graphical representation of the decision tree. The decision tree structure is displayed using the Image function from IPython.display.
The data is split into training and testing sets using train_test_split. This helps us evaluate how well our model performs on unseen data. A list of maximum depths to try in the Decision Tree classifier is defined. The training and testing accuracies are calculated for each depth by iterating through the maxDepth list. The accuracy scores for both training and testing sets are stored in arrays.
Finally, a plot is generated to visualize how training and testing accuracies vary with different maximum depths of the decision tree. This helps us understand how the model's performance changes as we adjust the depth of the tree.
In summary, this code demonstrates how to generate synthetic data, train a Decision Tree classifier, visualize the decision tree, and evaluate model performance based on different depths. It provides a structured approach to understanding and analyzing classification tasks using Decision Trees.
